{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch_jit (\n",
      "  %obs_0[FLOAT, batchx1x86x155]\n",
      ") initializers (\n",
      "  %version_number.1[FLOAT, 1]\n",
      "  %memory_size_vector[FLOAT, 1]\n",
      "  %network_body.observation_encoder.processors.0.dense.0.weight[FLOAT, 6665x13330]\n",
      "  %network_body.observation_encoder.processors.0.dense.0.bias[FLOAT, 6665]\n",
      "  %network_body.observation_encoder.processors.0.dense.2.weight[FLOAT, 256x6665]\n",
      "  %network_body.observation_encoder.processors.0.dense.2.bias[FLOAT, 256]\n",
      "  %network_body._body_endoder.seq_layers.0.weight[FLOAT, 256x256]\n",
      "  %network_body._body_endoder.seq_layers.0.bias[FLOAT, 256]\n",
      "  %network_body._body_endoder.seq_layers.2.weight[FLOAT, 256x256]\n",
      "  %network_body._body_endoder.seq_layers.2.bias[FLOAT, 256]\n",
      "  %action_model._continuous_distribution.log_sigma[FLOAT, 1x3]\n",
      "  %action_model._continuous_distribution.mu.weight[FLOAT, 3x256]\n",
      "  %action_model._continuous_distribution.mu.bias[FLOAT, 3]\n",
      ") {\n",
      "  %continuous_act_size_vector = Identity(%version_number.1)\n",
      "  %/network_body/observation_encoder/processors.0/Constant_output_0 = Constant[value = <Tensor>]()\n",
      "  %/network_body/observation_encoder/processors.0/Reshape_output_0 = Reshape(%obs_0, %/network_body/observation_encoder/processors.0/Constant_output_0)\n",
      "  %/network_body/observation_encoder/processors.0/dense/dense.0/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/network_body/observation_encoder/processors.0/Reshape_output_0, %network_body.observation_encoder.processors.0.dense.0.weight, %network_body.observation_encoder.processors.0.dense.0.bias)\n",
      "  %/network_body/observation_encoder/processors.0/dense/dense.1/LeakyRelu_output_0 = LeakyRelu[alpha = 0.00999999977648258](%/network_body/observation_encoder/processors.0/dense/dense.0/Gemm_output_0)\n",
      "  %/network_body/observation_encoder/processors.0/dense/dense.2/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/network_body/observation_encoder/processors.0/dense/dense.1/LeakyRelu_output_0, %network_body.observation_encoder.processors.0.dense.2.weight, %network_body.observation_encoder.processors.0.dense.2.bias)\n",
      "  %/network_body/observation_encoder/processors.0/dense/dense.3/LeakyRelu_output_0 = LeakyRelu[alpha = 0.00999999977648258](%/network_body/observation_encoder/processors.0/dense/dense.2/Gemm_output_0)\n",
      "  %/network_body/observation_encoder/Concat_output_0 = Concat[axis = 1](%/network_body/observation_encoder/processors.0/dense/dense.3/LeakyRelu_output_0)\n",
      "  %/network_body/_body_endoder/seq_layers/seq_layers.0/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/network_body/observation_encoder/Concat_output_0, %network_body._body_endoder.seq_layers.0.weight, %network_body._body_endoder.seq_layers.0.bias)\n",
      "  %/network_body/_body_endoder/seq_layers/seq_layers.1/Sigmoid_output_0 = Sigmoid(%/network_body/_body_endoder/seq_layers/seq_layers.0/Gemm_output_0)\n",
      "  %/network_body/_body_endoder/seq_layers/seq_layers.1/Mul_output_0 = Mul(%/network_body/_body_endoder/seq_layers/seq_layers.0/Gemm_output_0, %/network_body/_body_endoder/seq_layers/seq_layers.1/Sigmoid_output_0)\n",
      "  %/network_body/_body_endoder/seq_layers/seq_layers.2/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/network_body/_body_endoder/seq_layers/seq_layers.1/Mul_output_0, %network_body._body_endoder.seq_layers.2.weight, %network_body._body_endoder.seq_layers.2.bias)\n",
      "  %/network_body/_body_endoder/seq_layers/seq_layers.3/Sigmoid_output_0 = Sigmoid(%/network_body/_body_endoder/seq_layers/seq_layers.2/Gemm_output_0)\n",
      "  %/network_body/_body_endoder/seq_layers/seq_layers.3/Mul_output_0 = Mul(%/network_body/_body_endoder/seq_layers/seq_layers.2/Gemm_output_0, %/network_body/_body_endoder/seq_layers/seq_layers.3/Sigmoid_output_0)\n",
      "  %/_continuous_distribution/mu/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/network_body/_body_endoder/seq_layers/seq_layers.3/Mul_output_0, %action_model._continuous_distribution.mu.weight, %action_model._continuous_distribution.mu.bias)\n",
      "  %/_continuous_distribution/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\n",
      "  %/_continuous_distribution/Mul_output_0 = Mul(%/_continuous_distribution/mu/Gemm_output_0, %/_continuous_distribution/Constant_output_0)\n",
      "  %/_continuous_distribution/Add_output_0 = Add(%/_continuous_distribution/Mul_output_0, %action_model._continuous_distribution.log_sigma)\n",
      "  %/_continuous_distribution/Exp_output_0 = Exp(%/_continuous_distribution/Add_output_0)\n",
      "  %/RandomNormalLike_output_0 = RandomNormalLike[dtype = 1](%/_continuous_distribution/mu/Gemm_output_0)\n",
      "  %/Mul_output_0 = Mul(%/RandomNormalLike_output_0, %/_continuous_distribution/Exp_output_0)\n",
      "  %/Add_output_0 = Add(%/_continuous_distribution/mu/Gemm_output_0, %/Mul_output_0)\n",
      "  %/Clip_output_0 = Clip[max = 3, min = -3](%/Add_output_0)\n",
      "  %/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\n",
      "  %continuous_actions = Div(%/Clip_output_0, %/Constant_output_0)\n",
      "  %/Clip_1_output_0 = Clip[max = 3, min = -3](%/_continuous_distribution/mu/Gemm_output_0)\n",
      "  %/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\n",
      "  %deterministic_continuous_actions = Div(%/Clip_1_output_0, %/Constant_1_output_0)\n",
      "  %version_number = Identity(%version_number.1)\n",
      "  %memory_size = Identity(%memory_size_vector)\n",
      "  %continuous_action_output_shape = Identity(%continuous_act_size_vector)\n",
      "  return %version_number, %memory_size, %continuous_actions, %continuous_action_output_shape, %deterministic_continuous_actions\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"My Behavior-149971.onnx\")\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'My Behavior-149971.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "netron.start(\"My Behavior-149971.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Policy', 'global_step', 'Optimizer:value_optimizer', 'Optimizer:critic'])\n",
      "<class 'dict'>\n",
      "Dictionary keys: dict_keys(['Policy', 'global_step', 'Optimizer:value_optimizer', 'Optimizer:critic'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the state dictionary\n",
    "data = torch.load(\"My Behavior-149971.pt\", map_location=torch.device('cpu'))\n",
    "\n",
    "# Print available keys (layer names)\n",
    "print(data.keys())\n",
    "print(type(data))\n",
    "\n",
    "# if isinstance(data, dict):\n",
    "#     print(\"Keys in the state dictionary:\", data.keys())\n",
    "\n",
    "# for key, value in data.items():\n",
    "#     print(f\"{key}: {value.shape}\")  # Shape of each weight tensor\n",
    "\n",
    "# if isinstance(data, torch.nn.Module):\n",
    "#     print(data)  # Prints the model architecture\n",
    "\n",
    "if isinstance(data, torch.Tensor):\n",
    "    print(\"Tensor shape:\", data.shape)\n",
    "    print(\"Tensor data:\", data)\n",
    "elif isinstance(data, list):\n",
    "    print(f\"List of {len(data)} elements\")\n",
    "    print(data[:5])  # Print the first few elements\n",
    "elif isinstance(data, dict):\n",
    "    print(\"Dictionary keys:\", data.keys())\n",
    "else:\n",
    "    print(\"Unknown data type:\", type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state dictionary keys: dict_keys(['Policy', 'global_step', 'Optimizer:value_optimizer', 'Optimizer:critic'])\n",
      "The first key 'Policy' does not contain a tensor but a <class 'collections.OrderedDict'>.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the .pt file (assuming it's a state dictionary)\n",
    "# file_path = \"model.pt\"\n",
    "# state_dict = torch.load(file_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# Print available layer names (keys)\n",
    "print(\"Model state dictionary keys:\", data.keys())\n",
    "\n",
    "# Pick the first tensor in the state_dict\n",
    "first_key = list(data.keys())[0]  # Select the first key\n",
    "weights_tensor = data[first_key]  # Get the corresponding tensor\n",
    "\n",
    "# Ensure it's a tensor before converting\n",
    "if isinstance(weights_tensor, torch.Tensor):\n",
    "    # Convert to NumPy\n",
    "    weights_numpy = weights_tensor.cpu().numpy().flatten()\n",
    "\n",
    "    # Plot histogram of weights\n",
    "    plt.hist(weights_numpy, bins=50)\n",
    "    plt.title(f\"Weight Distribution for {first_key}\")\n",
    "    plt.xlabel(\"Weight Values\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"The first key '{first_key}' does not contain a tensor but a {type(weights_tensor)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
